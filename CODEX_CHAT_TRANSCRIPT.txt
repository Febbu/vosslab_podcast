Codex Project Transcript
Date: 2026-02-20
Location: /Users/pierre/job_campus/vosslab_podcast

Project Goal
- Build an automated weekly "podcast-style" summary of GitHub activity for user `vosslab`.
- Start simple: public repos only, last 7 days, repo-level activity only.
- Exclude forks for reporting.
- Later: generate narrated audio with Qwen3-TTS using multiple voices.

User Requirements Confirmed
- Weekly window: always last 7 days.
- Scope phase 1: original repos only (`fork=false`), repo-level updates only.
- Output should be automation-friendly and easy to extend.
- Use GitHub Actions for unattended weekly runs.
- English-only TTS initially.
- Keep host/analyst voices consistent each week; allow guest voice override sometimes.
- Use a separate Python environment for TTS; Conda chosen.

What Was Verified During Chat
- Repo `darrenoakey/tts` was checked and not identified as an Apple built-in TTS podcast-releases tool.
- User provided API JSON for `sort=created` and `sort=pushed`.
- Weekly digest for Feb 10-17, 2026 (UTC) was derived from provided data.

Files Created/Updated in This Project
- fetch_and_script.py
  - Fetches GitHub repos via API (created + pushed).
  - Filters last N days (default 7), excludes forks.
  - Writes `out/digest.json` and `out/script.txt`.
- .github/workflows/weekly.yml
  - Scheduled weekly run (Monday 09:00 UTC) + manual dispatch.
  - Uploads `out/` as workflow artifact.
- requirements.txt
  - Python dependency for digest script (`requests`).
- .gitignore
  - Ignores `.venv/`, `out/`, `__pycache__/`.
- README.md
  - Setup and usage for digest + TTS flow.
- tts_generate.py
  - Reads `out/script.txt` role lines (`HOST:`, `ANALYST:`, `GUEST:`).
  - Uses Qwen3-TTS CustomVoice model to synthesize per-role audio.
  - Writes `out/episode.wav`.
- voices.json
  - Stores stable role voices and optional guest override.

Local Test Results
- Digest script local run succeeded on user machine:
  - `out/digest.json` created.
  - `out/script.txt` created.
- Sandbox test initially failed due to network restrictions for pip in this environment.
- User local environment had internet and installed dependencies successfully.

Current Voice Config
- voices.json defaults:
  - host_voice: speaker_1
  - analyst_voice: speaker_2
  - guest_voice: speaker_3
  - guest_voice_override: null

Current Status
- Weekly text digest automation: implemented.
- Weekly publishing: NOT implemented.
- TTS script: implemented, needs local model/runtime setup and test run.
- MP3 conversion: not yet wired (current output is WAV).

How To Continue Next Session
1. Run weekly digest locally:
   - `python fetch_and_script.py`
2. Set up Conda TTS env and run audio generation:
   - `conda create -n qwen3-tts python=3.12 -y`
   - `conda activate qwen3-tts`
   - `pip install -U qwen-tts soundfile`
   - `python tts_generate.py`
3. Validate `out/episode.wav` quality and role voice mapping.
4. Add ffmpeg step to produce `out/episode.mp3`.
5. Add publishing step (optional): storage/feed/podcast host.

Notes for Future Codex
- User prefers concise, direct implementation steps.
- Keep solution pragmatic and incremental.
- Maintain this file as a running context log after each major session.

---
Session Update: 2026-02-20 (Codex Context Hardening)

What was actively done
- Added persistent transcript file:
  - `CODEX_CHAT_TRANSCRIPT.txt`
- Added project-level agent instructions:
  - `AGENTS.md`
- Verified transcript exists and contains prior project decisions and implementation status.

Why this was added
- Ensure future Codex sessions in this folder can recover context quickly.
- Reduce repeated setup/explanation in each new session.

Current project state
- Weekly digest automation exists (`fetch_and_script.py` + GitHub Actions schedule).
- Local digest test previously succeeded (`out/digest.json`, `out/script.txt`).
- TTS script exists (`tts_generate.py`) with role voice config (`voices.json`).
- Publishing step is still not implemented.

Immediate next steps
1. Run TTS environment setup (Conda) and execute `tts_generate.py`.
2. Validate generated audio quality and role-to-voice mapping.
3. Add optional WAV->MP3 conversion (ffmpeg).
4. Decide publishing target (artifact only vs hosted feed).

Instruction for future sessions
- Start by reading this transcript and `AGENTS.md`.
- Append a dated “Session Update” block after major progress.

---
Session Update: 2026-02-21 (Repo Initialization + GitHub Publish)

What changed
- Updated `.gitignore` to exclude `.venv_tts/` in addition to existing ignores.
- Created initial git commit on `main` with current project files.
- Created and published a new GitHub repository:
  - `https://github.com/Febbu/vosslab_podcast`
- Added remote `origin` and pushed `main`.

What was tested
- Verified git commit creation succeeded.
- Verified GitHub repo creation and first push succeeded.
- Verified local `main` tracks `origin/main`.

Next actions
1. Implement modular daily pipeline (`logs -> outline -> blog -> script -> audio`) as separate scripts.
2. Add daily GitHub Actions workflow for artifact chaining.
3. Integrate external TTS wrapper (`darrenoakey/tts`) in the final audio step.

---
Session Update: 2026-02-24 (Daily Pipeline Steps 1+2 Scaffold)

What changed
- Added daily pipeline scaffolding folders:
  - `pipelines/`
  - `config/`
  - `data/`
- Added shared utility module:
  - `pipelines/common.py`
- Added step 1 script:
  - `pipelines/01_logs_to_outline.py`
  - Reads JSON/JSONL logs and writes `data/YYYY-MM-DD/outline.json`.
- Added step 2 script:
  - `pipelines/02_outline_to_blog.py`
  - Reads outline and writes `data/YYYY-MM-DD/blog.md`.
- Added configuration files:
  - `config/characters.json` (4 characters, bios, default voices)
  - `config/settings.json` (timezone, run time, retention, model placeholders)
- Updated `README.md` with a new section for running daily modular steps 1 and 2.

What was tested
- Ran step 1 and step 2 locally for `2026-02-24`.
- Verified generated artifacts:
  - `data/2026-02-24/outline.json`
  - `data/2026-02-24/blog.md`

Next actions
1. Implement step 3 (`blog -> podcast_script`) with character-aware output (`script.json` + `script.txt`).
2. Implement step 4 (`podcast_script -> audio`) via the external TTS wrapper.
3. Add a daily GitHub Actions workflow chaining these artifacts.

---
Session Update: 2026-02-24 (Implemented Steps 3+4 + Runner)

What changed
- Implemented step 3:
  - `pipelines/03_blog_to_script.py`
  - Reads `data/YYYY-MM-DD/blog.md` and `config/characters.json`.
  - Writes `data/YYYY-MM-DD/script.json` and `data/YYYY-MM-DD/script.txt`.
- Implemented step 4:
  - `pipelines/04_script_to_audio.py`
  - Supports `--engine dry-run` (artifact validation) and `--engine qwen` (audio synthesis).
  - Writes `data/YYYY-MM-DD/audio_manifest.json` in dry-run mode.
  - Writes `data/YYYY-MM-DD/episode.wav` in qwen mode.
- Added orchestrator:
  - `run_daily.py`
  - Runs steps 1 -> 4 in order for a selected date.
- Updated `README.md` with commands for steps 3 and 4 and one-command run.

What was tested
- Step 3 local test succeeded:
  - Generated `script.json` and `script.txt` for `2026-02-24`.
- Step 4 dry-run local test succeeded:
  - Generated `audio_manifest.json` for `2026-02-24`.
- End-to-end dry-run test succeeded:
  - `python run_daily.py --date 2026-02-24 --audio-engine dry-run`
  - Regenerated outline, blog, script, and audio manifest artifacts.
- Step 4 qwen mode test in this Codex sandbox could not complete due network/DNS resolution failures to `huggingface.co`.

Next actions
1. On your machine, run step 4 with qwen in `.venv_tts` and verify `data/YYYY-MM-DD/episode.wav`.
2. Add daily GitHub Actions workflow to run `run_daily.py` and upload artifacts.
3. Replace or wrap step 4 engine with `darrenoakey/tts` integration path.

---
Session Update: 2026-02-24 (Apple TTS Fallback + MP3 Path)

What changed
- Added Apple TTS fallback engine to step 4:
  - `pipelines/04_script_to_audio.py --engine apple`
- Apple engine now uses macOS `say` with a single voice for full script text.
  - Default voice: `Samantha`
  - Optional override: `APPLE_TTS_VOICE` env var
- Added optional mp3 conversion to step 4:
  - `--mp3` creates `episode.mp3` using `ffmpeg`.
- Added duration validation for Apple output via `ffprobe`.
  - If generated audio has zero duration, script raises a clear error.
- Updated `run_daily.py`:
  - supports `--audio-engine apple`
  - supports `--mp3`
- Updated `README.md` with Apple TTS and mp3 commands.

What was tested
- In this Codex sandbox:
  - `--engine apple` command runs but generated AIFF had zero duration (environment limitation), and the new validation correctly fails with a clear message.
- Previously validated in this session:
  - dry-run and script generation steps are functioning.

Next actions
1. Run Apple engine locally on your machine terminal to confirm non-zero `episode.aiff` and `episode.mp3`.
2. If local Apple TTS succeeds, use Apple engine as default temporary production path.
3. Continue with daily GitHub Action wiring after local audio confirmation.

---
Session Update: 2026-02-24 (Presenter Simplification + Intro)

What changed
- Updated step 3 script builder to support no guests and no producer lines.
- Added presenter-count control:
  - `pipelines/03_blog_to_script.py --presenters {1|2}`
  - Default is now `1` presenter.
- Added presenter self-intros at the start of each generated script.
  - 1 presenter mode: host introduces themselves.
  - 2 presenter mode: host + analyst both introduce themselves.
- Updated orchestrator:
  - `run_daily.py --presenters {1|2}` now forwards presenter count to step 3.
- Updated README examples for presenter mode usage.

What was tested
- Step 3 tested with `--presenters 1` and `--presenters 2`.
- Verified `script.txt` output now starts with presenter introductions and contains only host/analyst roles.
- End-to-end dry-run tested with:
  - `python3 run_daily.py --date 2026-02-24 --presenters 2 --audio-engine dry-run`

Next actions
1. Use `--presenters 1` as default production mode initially.
2. Run Apple audio mode locally with `--presenters 1` and confirm voice quality.
3. Tune intro wording and speaking style once real logs are connected.

---
Session Update: 2026-02-24 (GitHub Source for Daily Pipeline)

What changed
- Updated step 1 to support direct GitHub repo activity input:
  - `pipelines/01_logs_to_outline.py --source github --github-user vosslab`
  - Filters by selected `--date` (UTC day window).
  - Captures non-fork repo create/push activity as outline events.
- Step 1 still supports local logs mode:
  - `--source logs --logs logs/latest.jsonl`
- Updated `run_daily.py` to pass source selection and GitHub username.
- Updated README commands to default to GitHub source and `vosslab` user.

What was tested
- Full pipeline dry-run tested successfully in logs mode:
  - `python3 run_daily.py --date 2026-02-24 --source logs --presenters 1 --audio-engine dry-run`
- GitHub source mode could not be tested in this Codex sandbox due network restrictions, but code path is wired.

Next actions
1. Run full pipeline on your machine with GitHub source and a known active day.
2. Use Apple or Qwen audio engine based on stability preference.
3. Add daily GitHub Actions schedule so it runs without your computer being on.

---
Session Update: 2026-02-24 (Presenter Identity + GitHub Update Visibility + Central Time)

What changed
- Host identity updated in `config/characters.json`:
  - Host name is now `Dr. Neil Voss`.
- Step 1 (`pipelines/01_logs_to_outline.py`) now supports explicit timezone boundaries for GitHub daily windows:
  - New flag: `--timezone` (default `America/Chicago`).
- Step 1 GitHub mode now outputs separate created vs updated metadata:
  - `created_count`, `updated_count`
  - `created_repos`, `updated_repos`
  - `top_points` now starts with both counts and highlights.
- Step 2 (`pipelines/02_outline_to_blog.py`) now renders clear sections:
  - New repos list
  - Updated repos list
  - Counts for both
- Step 3 bullet parsing adjusted to ignore placeholder `- None` items.
- `run_daily.py` now accepts and forwards `--timezone` to step 1 in GitHub mode.
- README commands updated to include `--timezone America/Chicago`.

What was tested
- Full pipeline dry-run tested in `logs` mode (sandbox-safe).
- Verified script output now starts with host intro using `Dr. Neil Voss`.
- Verified script signals include both "New repos today" and "Updated repos today" entries.

Next actions
1. Run `run_daily.py` in GitHub mode on a known active date and confirm updated repos are spoken.
2. If output is still sparse, increase spoken highlights in step 3 from 2 to 3-4 points.
3. Add daily GitHub Actions schedule after final local validation.

---
Session Update: 2026-02-24 (GitHub Highlight Ordering)

What changed
- Updated `pipelines/01_logs_to_outline.py` to keep repo highlight order from GitHub API (newest first) instead of alphabetical order.
- Deduplication now preserves order for both `created_repos` and `updated_repos`.

What was tested
- Code path updated and validated syntactically in project environment.

Next actions
1. Re-run the pipeline in GitHub mode for today and verify spoken highlights match latest updated repos.
